{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Image Downloader for jav.ink of yamachan01.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_agent import generate_user_agent\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from pathlib import Path\n",
    "import urllib.parse\n",
    "import requests\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  https://yamachan01.com/?tag=s-cute\n",
    "##  https://yamachan01.com/blog-entry-2324.html\n",
    "_category = \"s-cute\"\n",
    "_url = \"https://yamachan01.com/?tag=\"+_category\n",
    "\n",
    "_outputPath = \"../Dataset/Photos/Adult/yamachan01.com/\"+_category+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadAlbum(url):\n",
    "\n",
    "    if (len(url) < 10):\n",
    "        return\n",
    "\n",
    "    ##  If folder already exists, means already downloaded, skip it\n",
    "    path = Path(url)\n",
    "    pathName = urllib.parse.unquote(path.name)\n",
    "    filePath = os.path.join(_outputPath, pathName)\n",
    "    exist = os.path.exists(filePath)\n",
    "\n",
    "    ##  Create path\n",
    "    if (exist == False):\n",
    "        os.makedirs(filePath)\n",
    "\n",
    "    userAgent = generate_user_agent()\n",
    "    headers = {\"user-agent\":userAgent, \"referer\":_url}\n",
    "    httpRequest = requests.get(url=url, headers=headers)\n",
    "    soup = BeautifulSoup(httpRequest.text, \"html.parser\")\n",
    "    print(httpRequest.url)\n",
    "\n",
    "    objectList = soup.findAll(\"a\", attrs={\"target\":\"_blank\"})\n",
    "    if (objectList is None):\n",
    "        return\n",
    "\n",
    "    for imageObject in objectList:\n",
    "\n",
    "        imageURL = imageObject.get(\"href\")\n",
    "        if (imageURL is None):\n",
    "            print(\"### Image URL not found...\")\n",
    "            print(soup)\n",
    "            finish = True\n",
    "            return\n",
    "        \n",
    "        ##  Check if the link I want\n",
    "        if \"yamachan01\" not in imageURL:\n",
    "            continue\n",
    "\n",
    "        ##  Download image\n",
    "        imageURL = imageURL.rstrip()\n",
    "        imageFilename = imageURL.split(\"/\")[-1]\n",
    "        \n",
    "        array = imageFilename.split(\".jpg\")\n",
    "        imageFilename = array[0]+\".jpg\"\n",
    "        \n",
    "        ##  Check if file already exists\n",
    "        path = os.path.join(filePath, imageFilename)\n",
    "        if (os.path.isfile(path) == True):\n",
    "            continue\n",
    "\n",
    "        #print(\"Downloading \"+imageURL+\"...\")\n",
    "        imageURL = imageURL+\"?v=\"+str(randint(1, 100))\n",
    "        httpRequest = requests.get(imageURL, headers=headers, stream=True)\n",
    "        if (httpRequest.status_code != 200):\n",
    "            print(\"### Unable to download image...\\n\")\n",
    "            continue\n",
    "\n",
    "        ##  Set true to prevent image size zero\n",
    "        httpRequest.raw.decode_content = True\n",
    "\n",
    "        ##  Save image\n",
    "        with open(path, \"wb\") as file:\n",
    "            shutil.copyfileobj(httpRequest.raw, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album page #1...\n",
      "https://yamachan01.com/blog-entry-2324.html\n",
      "https://yamachan01.com/blog-entry-2224.html\n",
      "https://yamachan01.com/blog-entry-2117.html\n",
      "https://yamachan01.com/blog-entry-2016.html\n",
      "https://yamachan01.com/blog-entry-1685.html\n",
      "https://yamachan01.com/blog-entry-1622.html\n",
      "https://yamachan01.com/blog-entry-997.html\n"
     ]
    }
   ],
   "source": [
    "finish = False\n",
    "albumURL = _url\n",
    "userAgent = generate_user_agent()\n",
    "for i in range(1):\n",
    "\n",
    "    page = i+1\n",
    "    print(\"Album page #\"+str(page)+\"...\")\n",
    "\n",
    "    url = albumURL\n",
    "    if (page > 1):\n",
    "        url = albumURL+\"page/\"+str(page)+\"/\"\n",
    "    \n",
    "    headers = {\"user-agent\":userAgent, \"referer\":_url}\n",
    "    httpRequest = requests.get(url=url, headers=headers)\n",
    "    soup = BeautifulSoup(httpRequest.text, \"html.parser\")\n",
    "\n",
    "    albumList = soup.findAll(\"a\", attrs={\"rel\":\"nofollow\"})\n",
    "    if (albumList is None):\n",
    "        finish = True\n",
    "        break\n",
    "\n",
    "    finish = True\n",
    "    for linkObject in albumList:\n",
    "\n",
    "        ##  Check if it is Graphis album\n",
    "        url = linkObject.get(\"href\")\n",
    "        \n",
    "        if (url.startswith(\"https://yamachan01.com\") == False):\n",
    "            continue\n",
    "        \n",
    "        ##  Yes, Graphis album\n",
    "        #print(url)\n",
    "        downloadAlbum(url)\n",
    "        finish = False\n",
    "\n",
    "    if (finish == True):\n",
    "        break\n",
    "\n",
    "print(\"Finish all!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
